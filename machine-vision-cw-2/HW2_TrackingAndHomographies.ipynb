{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import io\n",
    "import cv2 as cv \n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import os # for reading all files in a folder\n",
    "pylab.rcParams['figure.figsize'] = (3, 2.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student Participant number: 05112003 \n",
    "(Please note that this isn't the one attributed to me by UCL, but should be a unique string, as suggested by Gabriel Brostow's email)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part H: Tracking and Homographies\n",
    "\n",
    "In this part we use Practical 7c to track the positions of the four corners of the square and project a cube into the images. \n",
    "\n",
    "TO DO: QUESTIONS TO THINK ABOUT...\n",
    "\n",
    "- Do the results look realistic? \n",
    "- If not then what factors do you think might be causing this\n",
    "\n",
    "\n",
    "TO DO: your routines for computing a homography and extracting a valid rotation and translation go in the code below. Tips:\n",
    "- you may define functions for T and H matrices respectively.\n",
    "- you may need to turn the points into homogeneous form before any other computation. \n",
    "- you may need to solve a linear system in Ah = 0 form. Write your own routines or using the builtin function 'svd'. \n",
    "- you may apply the direct linear transform (DLT) algorithm to recover the best homography H.\n",
    "- you may explain what & why you did in the report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Copy and paste the function HW2_Practical7c in here. \n",
    "def computeLikelihood(image, template):\n",
    "    #opencv's available methods - experiment with these\n",
    "    #careful what range the output is!\n",
    "    methods = [cv.TM_CCOEFF, cv.TM_CCOEFF_NORMED, cv.TM_CCORR,\n",
    "            cv.TM_CCORR_NORMED, cv.TM_SQDIFF, cv.TM_SQDIFF_NORMED]\n",
    "    \n",
    "    likelihood = cv.matchTemplate(image[:,:,2], template, methods[0])\n",
    "    # (You can also try converting the image to greyscale instead of using the third channel as above with \n",
    "    # cv.cvtColor(image, cv.COLOR_BGR2GRAY))\n",
    "    \n",
    "    #we can pad to make this the size of the input image (for easier indexing)   \n",
    "    pad_first = int(template.shape[0])\n",
    "    pad_second = int(template.shape[1])\n",
    "    pad_amounts = ((0, pad_first-1), (0, pad_second-1))\n",
    "    likelihood = np.pad(likelihood, pad_amounts, 'constant')\n",
    "    likelihood[likelihood<0] = 0 # to avoid negative weights \n",
    "    \n",
    "    # apply a 10x10 averaging filter for stability. You can experiment with different sizes. \n",
    "    kernel = np.ones((10,10),np.float32)/100\n",
    "    smoothed = cv.filter2D(likelihood,-1,kernel) \n",
    "    return smoothed \n",
    "\n",
    "def HW2_Practical7c(corner):\n",
    "    template = sp.io.loadmat(corner+'.mat')['pixelsTemplate']\n",
    "    #let's show the template\n",
    "    print('We are matching this template with shape: ', template.shape)\n",
    "    plt.imshow(template)\n",
    "    plt.show()\n",
    "\n",
    "    # Load all images in folder\n",
    "    images = []\n",
    "    iFrame = 0\n",
    "    folder = 'Pattern01/'\n",
    "    lst = os.listdir(folder)\n",
    "    lst.sort()\n",
    "\n",
    "    for frameNum in lst:\n",
    "        images.append(cv.imread(folder+frameNum))\n",
    "        iFrame += 1\n",
    "    # plot first image \n",
    "    plt.imshow(images[0])\n",
    "    plt.show()\n",
    "\n",
    "    imgHeight, imgWidth, colors = images[0].shape\n",
    "    numParticles = 2000;\n",
    "    weight_of_samples = np.ones((numParticles,1))\n",
    "\n",
    "    # TO DO: normalize the weights (may be trivial this time) [done]\n",
    "    weight_of_samples = weight_of_samples / np.sum(weight_of_samples)\n",
    "\n",
    "    # Initialize which samples from \"last time\" we want to propagate: all of\n",
    "    # them!:\n",
    "    samples_to_propagate = range(0, numParticles)\n",
    "\n",
    "    # ============================\n",
    "    # NOT A TO DO: You don't need to change the code below, but eventually you may\n",
    "    # want to vary the number of Dims (compare for example to lab 9b) \n",
    "    numDims_w = 2;\n",
    "    # Here we randomly initialize some particles throughout the space of w:\n",
    "    particles_old = np.random.rand(numParticles, numDims_w)\n",
    "    particles_old[:,0] = particles_old[:,0] * imgHeight\n",
    "    particles_old[:,1] = particles_old[:,1] * imgWidth\n",
    "    # ============================\n",
    "\n",
    "    #Initialize a temporary array r to store the per-frame MAP estimate of w. This is what we'll return in the end.\n",
    "    r = np.zeros((iFrame, numDims_w));\n",
    "\n",
    "    for iTime in range(iFrame):\n",
    "        print('Processing Frame', iTime)\n",
    "        # TO DO: compute the cumulative sume of the weights. [done] \n",
    "        cum_hist_of_weights = np.cumsum(weight_of_samples)\n",
    "        #print(weight_of_samples)\n",
    "\n",
    "        # ==============================================================\n",
    "        # Resample the old distribution at time t-1, and select samples, favoring\n",
    "        # those that had a higher posterior probability.\n",
    "        # ==============================================================\n",
    "        samples_to_propagate = np.zeros(numParticles, dtype=np.int32)\n",
    "\n",
    "        # Pick random thresholds in the cumulative probability's range [0,1]:\n",
    "        some_threshes = np.random.rand(numParticles)\n",
    "\n",
    "        # For each random threshold, find which sample in the ordered set is\n",
    "        # the first one to push the cumulative probability above that\n",
    "        # threshold, e.g. if the cumulative histogram goes from 0.23 to 0.26\n",
    "        # between the 17th and 18th samples in the old distribution, and the\n",
    "        # threshold is 0.234, then we'll want to propagate the 18th sample's w\n",
    "        # (i.e. particle #18).\n",
    "\n",
    "        for sampNum in range(numParticles): \n",
    "            thresh = some_threshes[sampNum]\n",
    "            for index in range (numParticles):\n",
    "                if cum_hist_of_weights[index] > thresh:\n",
    "                    break\n",
    "            samples_to_propagate[sampNum] = index\n",
    "\n",
    "        # Note: it's ok if some of the old particles get picked repeatedly, while\n",
    "        # others don't get picked at all.\n",
    "\n",
    "        # =================================================\n",
    "        # Visualize if you want\n",
    "        # =================================================\n",
    "        #plt.title('Cumulative histogram of probabilities for sorted list of particles')\n",
    "        #plt.plot(np.zeros(numParticles), some_threshes,'b.')\n",
    "        #plt.plot(range(0, numParticles), cum_hist_of_weights, 'rx-')\n",
    "        #which_sample_ids = np.unique(samples_to_propagate)\n",
    "        #how_many_of_each = np.bincount(np.ravel(samples_to_propagate))\n",
    "        #for k in range(len(which_sample_ids)):\n",
    "        #    plt.plot(which_sample_ids[k], 0, 'bo-', markersize = 3 * how_many_of_each[k], markerfacecolor='white')\n",
    "        #plt.xlabel('Indeces of all available samples, with larger blue circles for frequently re-sampled particles\\n(Iteration %01d)' % iTime)\n",
    "        #plt.ylabel('Cumulative probability');\n",
    "        #plt.show()\n",
    "        # =================================================\n",
    "        # =================================================\n",
    "\n",
    "        # Predict where the particles we sampled from the old distribution of \n",
    "        # state-space will go in the next time-step. This means we have to apply \n",
    "        # the motion model to each old sample.\n",
    "        particles_new = np.zeros_like(particles_old)\n",
    "        for particleNum in range(numParticles):\n",
    "            # TO DO: Incorporate some noise, e.g. Gaussian noise with std 20,\n",
    "            # into the current location (particles_old), to give a Brownian\n",
    "            # motion model.\n",
    "            old_idx = samples_to_propagate[particleNum]\n",
    "            noise = np.random.normal(0, 20, size=(2,))\n",
    "            particles_new[particleNum, :] = particles_old[old_idx, :] + noise\n",
    "            \n",
    "        # TO DO: Not initially, but change the motion model above to have\n",
    "        # different degrees of freedom, and optionally completely different\n",
    "        # motion models. See Extra Credit for more instructions.\n",
    "\n",
    "        #calculate likelihood function\n",
    "        likelihood = computeLikelihood(images[iTime], template)\n",
    "\n",
    "        #plot results\n",
    "        f, axarr = plt.subplots(1, 2)\n",
    "        axarr[0].imshow(images[iTime])\n",
    "        axarr[0].set_title('Particles')\n",
    "        # now draw the particles onto the image\n",
    "        axarr[0].plot(particles_new[:,1]+template.shape[1]/2, particles_new[:,0]+template.shape[0]/2, 'rx')\n",
    "\n",
    "        #plot the likelihood\n",
    "        axarr[1].imshow(likelihood)\n",
    "        axarr[1].set_title('Likelihood')\n",
    "\n",
    "        # From here we incorporate the data for the new state (time t):\n",
    "        # The new particles accompanying predicted locations in state-space\n",
    "        # for time t, are missing their weights: how well does each particle\n",
    "        # explain the observations x_t?\n",
    "        for particleNum in range(numParticles):\n",
    "\n",
    "            # Convert the particle from state-space w to measurement-space x:\n",
    "            # Note: that step is trivial here since both are in 2D space of image\n",
    "            # coordinates\n",
    "\n",
    "            # Within the loop, we evaluate the likelihood of each particle:\n",
    "            particle = particles_new[particleNum, :]\n",
    "            # Check that the predicted location is a place we can really evaluate\n",
    "            # the likelihood.\n",
    "            inFrame = particle[0] >= 0.0 and  particle[0] <= imgHeight and particle[1] >= 0.0 and particle[1] <= imgWidth\n",
    "            if inFrame:\n",
    "                minX = particle[1]\n",
    "                minY = particle[0]\n",
    "\n",
    "                weight_of_samples[particleNum] = likelihood[int(minY), int(minX)]\n",
    "\n",
    "            else:\n",
    "                weight_of_samples[particleNum] = 0.0\n",
    "\n",
    "        # TO DO: normalize the weights [done]                         \n",
    "        sum_weights = np.sum(weight_of_samples)\n",
    "        weight_of_samples = weight_of_samples / sum_weights\n",
    "        \n",
    "        # find the location of the particle with highest weight\n",
    "        indices = np.argsort(weight_of_samples,0)\n",
    "        bestScoringParticles = particles_new[np.squeeze(indices[-15:]), :]\n",
    "        plt.plot(bestScoringParticles[-1:,1], bestScoringParticles[-1:,0], 'rx')\n",
    "        # Return the MAP of middle position. Add template.shape/2 because matchTemplate finds the position of the upper left corner \n",
    "        # of the template. We want to plot the centre of the template. \n",
    "        r[iTime,:] = bestScoringParticles[-1,1]+template.shape[1]/2,bestScoringParticles[-1,0]+template.shape[0]/2\n",
    "        print(r[iTime,:])   \n",
    "        plt.show()\n",
    "\n",
    "        #print the original image and the position of the tracked corner.\n",
    "        plt.imshow(images[iTime])\n",
    "        plt.plot(r[iTime,0],r[iTime,1],'rx')\n",
    "        plt.show()\n",
    "        # Now we're done updating the state for time t. \n",
    "        # For Condensation, just clean up and prepare for the next round of \n",
    "        # predictions and measurements:\n",
    "        particles_old = particles_new\n",
    "\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# instead of running the code here, you can also save the output of each function in a numpy array in HW2_Practical7c \n",
    "# and load it here. This could be handy if you need different hyperparameters for each corner.\n",
    "LLs = HW2_Practical7c( 'll' )\n",
    "LRs = HW2_Practical7c( 'lr' )\n",
    "ULs = HW2_Practical7c( 'ul' )\n",
    "URs = HW2_Practical7c( 'ur' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure dicussion: \n",
    "This is the same thing as in the HW2_Practical7c, where the figures above show the evolution of a particle filter tracking each corner of a black square in turn across frames. Initially, the particles are scattered randomly. At the start, particles can be found in other areas of high probability, but in the end they all stabilise tightly around the corner.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all images in folder\n",
    "images = []\n",
    "nFrame = 0\n",
    "folder = 'Pattern01/'\n",
    "lst = os.listdir(folder)\n",
    "lst.sort()\n",
    "\n",
    "for frameNum in lst:\n",
    "    images.append(cv.imread(folder+frameNum))\n",
    "    nFrame += 1\n",
    "# plot first image \n",
    "plt.imshow(images[0])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Coordinates of the known target object (a dark square on a plane) in 3D:\n",
    "XCart = np.array([[-50, -50,  50,  50],\n",
    "          [50, -50, -50,  50],\n",
    "            [0, 0, 0, 0]])\n",
    "\n",
    "# These are some approximate intrinsics for this footage.\n",
    "K = np.array([[640, 0, 320],\n",
    "          [0, 512, 256],\n",
    "            [0, 0, 1]])\n",
    "\n",
    "# Define 3D points of wireframe object.\n",
    "XWireFrameCart = np.array([[-50, -50,  50,  50, -50, -50,  50,  50],\n",
    "          [50, -50, -50,  50, 50, -50, -50,  50],\n",
    "            [0, 0, 0, 0, -100, -100, -100, -100, ]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure dicussion: \n",
    "The figure above is a plot of the first image contained in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy pasting functions to calculate the extrinsic matrix\n",
    "def solveAXEqualsZero(A):\n",
    "    # TODO: Write this routine - it should solve Ah = 0. You can do this using SVD. Consult your notes! \n",
    "    # Hint: SVD will be involved. \n",
    "  \n",
    "    # We compute the SVD of A\n",
    "    U, S, Vt = np.linalg.svd(A)\n",
    "    \n",
    "    # The vector h is the last column of V corresponding to the smallest singular value\n",
    "    h = Vt[-1, :]\n",
    "    \n",
    "    # We normalize h if we want the last element to be 1.\n",
    "    if abs(h[-1]) > 1e-12:\n",
    "        h = h / h[-1]\n",
    "    return h\n",
    "\n",
    "def calcBestHomography(pts1Cart, pts2Cart):\n",
    "    # This function should apply the direct linear transform (DLT) algorithm to calculate the best \n",
    "    # homography that maps the cartesian points in pts1Cart to their corresonding matching cartesian poitns \n",
    "    # in pts2Cart.\n",
    "    \n",
    "    # This function calls solveAXEqualsZero. Make sure you are wary of how to reshape h into a 3 by 3 matrix. \n",
    "\n",
    "    n_points = pts1Cart.shape[1]\n",
    "    \n",
    "    # TODO: replace this:\n",
    "    H = np.identity(3)\n",
    "\n",
    "    # TODO: \n",
    "    # First convert points into homogeneous representation\n",
    "    # Hint: we've done this before  in the skeleton code we provide.\n",
    "    pts1Hom = np.vstack((pts1Cart, np.ones((1, n_points))))\n",
    "    pts2Hom = np.vstack((pts2Cart, np.ones((1, n_points))))\n",
    "\n",
    "    # TODO: \n",
    "    # Then construct the matrix A, size (n_points * 2, 9)\n",
    "    # Consult the notes!\n",
    "    A = np.zeros((2 * n_points, 9))\n",
    "\n",
    "    for i in range(n_points):\n",
    "        x,  y  = pts1Hom[0, i],  pts1Hom[1, i]\n",
    "        x_p, y_p = pts2Hom[0, i], pts2Hom[1, i]\n",
    "        A[2*i, :]   = [0, 0, 0, -x, -y, -1,  y_p*x,  y_p*y,  y_p]\n",
    "        A[2*i+1, :] = [x, y, 1,  0,  0,  0, -x_p*x, -x_p*y, -x_p]\n",
    "\n",
    "    # TODO: \n",
    "    # Solve Ah = 0 using solveAXEqualsZero and get h.\n",
    "    h = solveAXEqualsZero(A)\n",
    "\n",
    "    # TODO: \n",
    "    # Reshape h into the matrix H, values of h go first into rows of H\n",
    "    H = h.reshape(3, 3)\n",
    "    \n",
    "    return H\n",
    "\n",
    "def projectiveCamera(K,T,XCart):\n",
    "    ##TODO\n",
    "    # The goal of this function is to project points in XCart through projective camera\n",
    "    # defined by intrinsic matrix K and extrinsic matrix T. In essence, this function takes a set of points \n",
    "    # in 3D world space, XCart, and projects them into camera image space by applying the extrinsic matrix T \n",
    "    # and then applying the intrinsic matrix K.\n",
    "    # \n",
    "    # There are three steps.\n",
    "    # 1) Move from world space to camera space. \n",
    "    #            camera space points = extrinsics T * world space points \n",
    "    #\n",
    "    # 2) Applying the intrinsics matrix to the camera space points after normalizing\n",
    "    #           homogeneous image space points = K * normalized camera space points\n",
    "    # \n",
    "    # 3) Move to image space cartesian points from image space homogeneous points, involves a \n",
    "    # normalization using the third row.\n",
    "    \n",
    "    # TODO: Convert Cartesian 3d points XCart to homogeneous coordinates XHom\n",
    "    n = XCart.shape[1]\n",
    "    XHom = np.vstack((XCart, np.ones((1, n))))\n",
    "\n",
    "    # TODO: Apply extrinsic matrix to XHom, to move to frame of reference of camera\n",
    "    xCamHom = T @ XHom \n",
    "\n",
    "    # TODO: Project points into normalized camera coordinates xCamHom (remove 4th row)\n",
    "    xCamCart = xCamHom[:3, :] / xCamHom[3, :]\n",
    "\n",
    "    # TODO: Move points to image coordinates xImHom by applying intrinsic matrix\n",
    "    xImHom = K @ xCamCart\n",
    "\n",
    "    # TODO: Convert points back to Cartesian coordinates xImCart\n",
    "    XImCart = xImHom[:2, :] / xImHom[2, :]\n",
    "\n",
    "    return XImCart\n",
    "\n",
    "def estimatePlanePose(XImCart,XCart,K):\n",
    "    # The goal of this function is to estimate the pose of a plane relative to camera (extrinsic matrix)\n",
    "    # given points in image space xImCart, points in 3D world space XCart, and an intrinsics matrix K.\n",
    "\n",
    "    # TODO: Convert Cartesian image points XImCart to homogeneous representation XImHom\n",
    "    n = XImCart.shape[1]\n",
    "    XImHom = np.vstack((XImCart, np.ones((1, n))))\n",
    "    \n",
    "    # TODO: Convert image co-ordinates XImHom to normalized camera coordinates XCamHom    \n",
    "    K_inv = np.linalg.inv(K)\n",
    "    XCamHom = K_inv @ XImHom\n",
    "    xCamNorm = XCamHom[:2, :] / XCamHom[2, :]\n",
    "    \n",
    "    # TODO: Estimate homography H mapping homogeneous (x,y) coordinates of positions\n",
    "    # in real world to XCamHom (convert XCamHom to Cartesian, calculate the homography) -\n",
    "    # use the routine you wrote for Practical 1B\n",
    "    XCart2D = XCart[:2, :]\n",
    "    H_est = calcBestHomography(XCart2D, xCamNorm)\n",
    "          \n",
    "    # TODO: Estimate first two columns of rotation matrix R from the first two\n",
    "    # columns of H using the SVD. NOTE: You do not need to transpose v from linalg.svd    \n",
    "    h1 = H_est[:, 0]\n",
    "    h2 = H_est[:, 1]\n",
    "    h3 = H_est[:, 2]\n",
    "    Q = np.column_stack((h1, h2))\n",
    "    U, S, Vt = np.linalg.svd(Q)\n",
    "    R12 = U[:, :2] @ Vt\n",
    "    r1 = R12[:, 0]\n",
    "    r2 = R12[:, 1]\n",
    "\n",
    "    # TODO: Estimate the third column of the rotation matrix by taking the cross\n",
    "    # product of the first two columns\n",
    "    r3 = np.cross(r1, r2)\n",
    "    R = np.column_stack((r1, r2, r3))\n",
    "        \n",
    "    # TODO: Check that the determinant of the rotation matrix is positive - if\n",
    "    # not then multiply last column by -1.\n",
    "    if np.linalg.det(R) < 0:\n",
    "        R[:, 2] = -R[:, 2]\n",
    "    \n",
    "    # TODO: Estimate the translation t by finding the appropriate scaling factor k\n",
    "    # and applying it to the third colulmn of H\n",
    "    norm_h1 = np.linalg.norm(h1)\n",
    "    norm_h2 = np.linalg.norm(h2)\n",
    "    k = (norm_h1 + norm_h2) / 2.0\n",
    "    t = h3 / k\n",
    "    \n",
    "    # TODO: Check whether t_z is negative - if it is then multiply t by -1 and\n",
    "    # the first two columns of R by -1.\n",
    "    if t[2] < 0:\n",
    "        R[:, 0] = -R[:, 0]\n",
    "        R[:, 1] = -R[:, 1]\n",
    "        t = -t\n",
    "            \n",
    "    # TODO: Assemble transformation into matrix form\n",
    "    T = np.eye(4)\n",
    "    T[0:3, 0:3] = R\n",
    "    T[0:3, 3] = t\n",
    "    \n",
    "    return T \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================\n",
    "for iFrame in range(nFrame):\n",
    "    if iFrame % 10 == 0:\n",
    "        xImCart = np.array([LLs[iFrame,:].T, ULs[iFrame,:].T, URs[iFrame,:].T, LRs[iFrame,:].T]).T\n",
    "\n",
    "        # get a frame from footage \n",
    "        im = images[iFrame]\n",
    "\n",
    "        # Draw image and 2d points\n",
    "        plt.imshow(im)\n",
    "        plt.scatter(x = xImCart[0,:], y = xImCart[1,:],c = 'r')\n",
    "        plt.show()\n",
    "\n",
    "        #TO DO: Use your routine to calculate TEst the extrinsic matrix relating the\n",
    "        #plane position to the camera position.\n",
    "        TEst = estimatePlanePose(xImCart, XCart, K);\n",
    "    \n",
    "        # TO DO: Draw a wire frame cube using data XWireFrameCart. You need to\n",
    "        # 1) project the vertices of a 3D cube through the projective camera;\n",
    "        # 2) draw lines betweeen the resulting 2d image points.\n",
    "        # Note: CONDUCT YOUR CODE FOR DRAWING XWireFrameCart HERE\n",
    "\n",
    "        XWireFrameCartProjected = projectiveCamera(K, TEst, XWireFrameCart)\n",
    "\n",
    "        # We define edges of the cube:\n",
    "        edges = np.array([\n",
    "       [0,1], [1,2], [2,3], [3,0], \n",
    "       [4,5], [5,6], [6,7], [7,4], \n",
    "       [0,4], [1,5], [2,6], [3,7]   \n",
    "        ])\n",
    "\n",
    "        plt.imshow(im)\n",
    "        plt.plot(xImCart[0, :], xImCart[1, :], 'r.')\n",
    "\n",
    "        for e in edges:\n",
    "           plt.plot(\n",
    "                [XWireFrameCartProjected[0, e[0]], XWireFrameCartProjected[0, e[1]]],\n",
    "              [XWireFrameCartProjected[1, e[0]], XWireFrameCartProjected[1, e[1]]],\n",
    "                'g-'\n",
    "            )    \n",
    "\n",
    "        plt.axis('off')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure discussion:\n",
    "Included above are every 10th frame from the data. This was done in the interest of storage space and to illustrate the result better. The figures contain red dots, marking out the corners of the black square. These dots are used to place a 3D cube in the world space. Most frames give good results, as they give convicing renditions of the cube. Some on the other hand perform a lot worse, such as the last displayed image. The results look in general realistic, and when they don't, it could be an issue with the estimation linked to performing the Direct Linear Transformation (DLT). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: \n",
    "Consider this simplistic example, and mention at least two actions or changes we could make to improve the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer - Question 1: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are some suggestions to improve the results: \n",
    "\n",
    "**Use a more realistic motion model:** Instead of applying pure Brownian noise with a standard deviation to update particle positions, we could incorporate velocity or acceleration states into the model. This would be more physically plausible and would help the tracker adapt to the movement patterns, which might make the dots allign better.\n",
    "\n",
    "**Try other resampling techniques:** Instead of threshold-based resampling, we could use systematic (low-variance) or stratified resampling. These can help maintain diversity, as multinomial resampling often resamples only the highest weight particles and discards some informative ones. By preserving more medium weight particles,we could improve the model's performance in the face of movement for example.  \n",
    "\n",
    "**Adding more features to track** For now we are only tracking the four corners of the black square, we could add more reference points to improve the results, such as the centre of the square of the middle of the vertices. This woul dbe more computationaly expensive but might improve how the 3D cube aligns on the black square. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
